[ { "title": "100DaysOfHomelab 20/100 - Workplace Weariness and Karefree K8s", "url": "/posts/100DaysOfHomeLab-Day20-Workplace-Weariness-and-Karefree-K8s/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, kubernetes, k8s, k3s", "date": "2022-10-18 00:00:00 +0000", "snippet": "Well, as I’ve mentioned a few times previously, I have a new job. I’m out of training, and that’s great, I really love what I do (entry-level IAM Engineer), and it’s certianly interesting! Unfortunately, as the learning curve is pretty steep, it leaves me a bit “brain dead” at the end of the day. Totally worth it! Also, totally a buzzkill for the whole #100DaysofHomeLab challenge. Still, I’m not giving up in any way, I’m still excited to be working on this! It does mean, however, that I may be posting about once a week for the next month or two (or three…). So things will be a bit slower than I’d like, but I still have to take time for stuff around the house, my family, and frankly my mental health. I’m not a kid, and I’ve been working a long time…I’ve already made all of those mistakes, and I’m not interested in making them again. I’m not interested in making them again.My next move (and I have been poking at this behind the scenes, at least every other day, just not enough to write about) is to transition from Docker containers run by themselves, and then via Docker-Compose, to finally take the plunge into Kubernetes. I’m leaning towards K3S right now. The Rancher people seem pretty responsive, and it’s fairly well documented. The eventual goal is to connect my internal network to the outside internet via a loadbalancer. I’d like to set up virtual docker networks to keep some segmentation, and make it so that only the services that I want to be available to me (and friends) are exposed, with my internal services only available remotely via VPN, just for that extra layer of seperation. This is what I’m looking at:Proposed Homelab Architecture" }, { "title": "100DaysOfHomelab 19/100 - Dropping Containers, Building Machines", "url": "/posts/100DaysOfHomeLab-Day19-Dropping-Containers-Building-Machines/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, media, jellyfin, vms, ubuntu, virtualbox", "date": "2022-10-05 00:00:00 +0000", "snippet": "I missed a day blogging, but I did work on my current project for about an hour yesterday. Still not going to count it, since I’m not sure. Basically, while Emby is pretty good, I really don’t like the subscription thing. And since I couldn’t get Jellyfin working in a container, like I wanted it to be (and will still work on from time-to-time) I decided to spin up a small Ubuntu VM in VirtualBox, and just leave that running. Can’t wait to get some hardware that will actually allow me to run ProxMox on it. I’m considering something like the ZimaBoard 832 - which has a quad-core Celeron processor and 8GB of RAM, 2 SATA ports, a PCIE port, and 2x 1GB Ethernet. I might get two, and use one to OpnSense. I don’t have the funds to upgrade to a 10-gig home network yet, so that’s not an issue at the moment. And for $200…it sounds like a pretty decent deal.In any case, I’ve spent the last couple of days setting up Jellyfin the way that I want it (for now…I want it behind Traefik eventually, once I get that going) and moving around movies, tv shows, books, music, etc. Jellyfin is certainly not a replacement for Calibre, but since the data storage that I’m using for it is also where I keep my Calibre library…I figured it doesn’t hurt anything to link it there. It might work better if it wasn’t set up as a Calibre library since that is all sorted by author. I’m planning to eventually take a look at the book naming convention documentation for Jellyfin, and see if I have to set things up in a certain way to make it work decently, or if there are some settings that I can tweak manually. Heck, once I get the time, I may look into contributing a plugin or something that would make reading a Calibre-type library into a usable experience." }, { "title": "100DaysOfHomelab 18/100 - Doing the Emby Shuffle", "url": "/posts/100DaysOfHomeLab-Day18-Doing-the-Emby-Shuffle/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, media, emby", "date": "2022-10-03 00:00:00 +0000", "snippet": "Finally!So, I finally have a media server set up! I did drop Jellyfin (for now…it really looks like the best thing going if you don’t want a subscription) and switched to Emby. It was extraordinarily easy to set up…just copy the docker-config text from the page on Docker Hub. This is another image by linuxserver.io, and it runs great…just like everything from them that I’ve tried, other than Jellyfin.Tweaking the KnobsMost of the day’s time has been spent tweaking the server setting, setting up accounts for my family, and organizing media. Currently, I am using a 4TB drive that is connected to my router, and is also where my Calibre library resides. I made a mistake to begin with, and just was storing the files within my WSL instance. I thought that I had set this Windows box up where all “store” apps were stored on D:, which is 8TB. I was incorrect…everything was being stored on C:, which is a 1TB NVME. Needless to say, I ran out of space quite quickly. Until all of that gets moved again across the network, that computer is pretty much out of commission…and I don’t have 10GB networking set up yet. So…I guess I’m glad that I write these on my Mac!" }, { "title": "100DaysOfHomelab 17/100 - Jellyfin Stings", "url": "/posts/100DaysOfHomelab-Day17-Jellyfin-Stings/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, frustration, jellyfin, permissions", "date": "2022-10-02 00:00:00 +0000", "snippet": "So today, there is Jellyfin. Well, there is a container that has Jellyfin in it, but I can’t really access it. This is frustrating on several levels. The issue is permissions. I just deleted a long rant about linuxserver.io and their incomprehensible decision to utterly override user choice on permissions for the /config directory in the image. I tried a different image with another image (jellyfin/jellyfin) but it had other issues. Frankly, I’m sick of it. I’ll probably go back to using Plex unless someone has an idea to make it work correctly. The issues on the GitHub page were…well, frankly, they were completely unhelpful, with overbearing and rude contributors. Seriously reconsidering ever using anything else from linuxserver.io. I’m not a big fan of condescension.So I wrestled with this for several hours, to no avail. Given that, I’ll be dropping the Jellyfin part of this project for now. Hopefully, as I continue to learn, I’ll be able to come back to it and get it working in the near future. That being said, I tried Emby just on a lark…it set up without issue, using the instructions from Docker Hub. No issues at all so far. This is also an image from linuxserver.io, which leads me to believe that the real issue here was Jellyfin. Who knows?" }, { "title": "100DaysOfHomelab 16/100 - Nuke It From Orbit", "url": "/posts/100DaysOfHomelab-Day16-Nuke-It-From-Orbit/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, frustration", "date": "2022-10-01 00:00:00 +0000", "snippet": "Hello again! Maybe “Hello World” might be appropriate, here. As you can probably tell from the title, today’s exercise in futility with Docker finally got to the point where I tore it all down. I deleted all of the volumes, I deleted all of the images, and I even deleted everything out of my docker-compose file and started over.I am pleased to announce that as of now, almost everything is working! Heimdall is up and running without issue, and now has a linked volume so that I don’t have to re-pin services every time I take down the container. PostgreSQL is up and running without issue, and connection via PGadmin has been seemless. I even got Redis up and running, along with Redis Commander, all working well. Both databases have their own volumes for persistence.I did create some media folders on the shared drive on my network, and mounted them locally. I’m attempting to put up Jellyfin, to allow media sharing, etc. So far, this is the only service that isn’t up and working normally, but I’m not frustrated. It’s late enough that tonight is now tomorrow, and I’ve got a good start. So poking at Jellyfin (it appears to be a permissions issue, which I really need to learn about with Docker anyway) is the first order of business tomorrow, once I get into the homelab.Also, welcome to Cybersecurity Awareness Month! As a PSA: do not refer to Cybersecurity Awareness Month as CSAM. That is an acronym that already means something, and it’s something that none of us want to be associated with…well, at least I hope so. If you do, please no longer read this blog, and remove me from any social media where you may be following me because…ew. All that being said, once I get Jellyfin up and working, then I’ll be turning my attention to more security-focused projects. A to-do list:To Do for Cybersecurity Awareness Month Set up a load balancer (optional, but preferable) Set up a VPN for access when away from home Set up Grafana services and get them integrated Grafana (um, duh) Loki Prometheus (Maybe more, I don’t know yet) See if Grafana can be made into something like a SIEM, or if there is an app that is a SIEM that integrates with it Set up Traefik to serve web pages with automated LetsEncrypt updates for https support If ALL of that is done, or as done as I’m happy with, then I’ll go back to attempting to set up Calibre in a container. This is an add-on because I already have Calibre running locally with the library on a network drive. Ironically, Calibre is running on the box that I run Docker on…so the IP address for the server won’t even change Waiiiiiit a minute, that’s something to consider: stopping the Calibre server before trying to start the container with a conflicting port… " }, { "title": "100DaysOfHomelab 15/100 - The Break and More Docker Compose", "url": "/posts/100DaysOfHomelab-Day15-The-Break-and-More-Docker-Compose/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose", "date": "2022-09-30 00:00:00 +0000", "snippet": "So if you’re one of the (maybe 1-2) people who follow me blogging here, then you probably have noticed that I haven’t posted in a week. Well, I started a new job on Monday. Frankly, after getting off of work each day, I had plenty of time to work on things…I just didn’t have the mental bandwidth! Training is always a lot of fun, but it can be kind of draining, mentally speaking. So I finished today, and (since I’ve got a couple of days off in front of me), I picked back up working in Docker.Mostly today is simply working on updating my docker-compose file and attempting to get Calibre to recognize the volume with all of my books in it. The actual directory that the books are in are on a hard drive connected to my router, which I can access via SMB. So to try and make this work, I have mounted the samba share to the directory that I wish to use as the volume. The problem is…it’s not working. I need to investigate and see if this is something that is normal in Docker, and I need to do a different workaround, or if I’m simply declaring the volume incorrectly. I may mess around with a PostgreSQL container, since I would also want to mount a volume for it, and it’s a little more straightforward than something like Calibre." }, { "title": "100DaysOfHomelab 13-14/100 - Docker Compose and Networking", "url": "/posts/100DaysOfHomelab-Day13-14-Docker-Compose-and-Networking/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose, docker-networking, networking, layer3, ipvlan", "date": "2022-09-24 00:00:00 +0000", "snippet": "So I didn’t post anything yesterday. There was really nothing to talk about beyond: I made a bunch of tiny edits in my docker-compose.yml file, pushed them to GitHub one by one, and pulled them down to my test machine. I would literally make an edit in Sublime on my macbook, commit/push the change, and then on my VM, I would hit up-arrow twice and enter to send git pull, followed by another two up-arrows and enter to send sudo docker-compose up -d over and over again.I had circular references for links. I removed all the links, because I got to looking at the docker documentation, and they are no longer recommended. You get almost all of the functionality by using user-defined networking. Awesome!Except…user-defined networking in docker-compose is a little nightmarish unless you want to use the default “bridge” network with a custom name. What I’m trying to do is use ipvlan L3, as that honestly seems like the best fit for my use case here. I want to be able to set up specific subnets for classes of containers…like using 10.1.1.0/24 for general-purpose things, like Heimdall and Yacht. I’d like to use 10.1.2.0/24 specifically for logging and security related containers. It goes on from there. Setting up the static route in my router really isn’t the problem, it’s not a great router, but it does have the functionality. The issue here (I can create the network manually using docker network) is that I can’t get docker-compose to like it. I get the error that ipvlan is not a valid driver. I’ve been digging through the documentation for docker compose, and, well…have you ever read Microsoft documentation from the 90s? I think Docker hired the same people. Their documentation is technically correct, but almost completely worthless if you’re looking for a specific thing. Terrible application of technical writing. Still, it does have the information in there, it’s just hard to find. I’ll keep digging for it. Apparently this isn’t a terribly common use-case, as some basic Googling led me to completely irrelevant YouTube videos and the Docker docs. So, it’s going to be a lot of Google-Fu to find the information that I need.I’m also thinking about taking tomorrow “off” of homelabbing, and just play some video games. I’ve completed all of my assignments for my class in school, and I start my new position on Monday…a little bit of celebration seems in order. Not sure if I’ll keep these classes for next semester (I’m registered, but next week is a “break” week, and then I have the first week of class for drop/add) or not, it’s really going to depend on the onboarding process. That said, I don’t actually need this degree at this point in my career…I’m just getting started, and a Master’s is just as likely to hurt as to help my prospects." }, { "title": "Skills: What are the Most Important Ones in Tech?", "url": "/posts/Skills-Most-Important-In-Tech/", "categories": "Security Thoughts", "tags": "infosec, cybersecurity, tech-skills, soft-skills, wfh", "date": "2022-09-22 00:00:00 +0000", "snippet": "SummaryI see a lot of discussion online about skills, and what are the most important skills to have to land a job in tech. I don’t have a huge amount of experience in tech jobs (yet) short of technical support, but I do have a great deal of business experience…and I talk to a lot of people.Tech SkillsTech skills have to be the most important for a tech job, right? Well, they’re certainly important, especially since you can’t do the job without those skills. A lot of people say:“I’m looking to transition into tech, what should I learn?”That’s an interesting question, and likely broader than what the person asking actually means. What kind of tech do you want to go into? There’s all sorts of stuff that you can do. Do you want to play with networks and hardware, develop applications or back-end infrastructure? Do you want to design and implement cloud architecture? Security? Tech sales? Management? Project Management? There are dozens more to choose from.“OK, I want to get into security in tech. Cybersecurity. What should I learn?”Um, that doesn’t really narrow it down. Are you wanting to work with Identity and Access Management (IAM)? Do you want to do pentesting? Security Operations Center (SOC) analyst? Threat Intelligence? Digital Forensics and/or Incident Response (DFIR)? Do you want to write policies? Training? Oversee compliance? Security Architect is a thing too. Each of these areas has dozens of sub-specialties and cloud variants, not to mention the dozens and dozens of sorts of roles that I haven’t listed.One of the hardest things to do once you decide what to do in tech is to decide what skills you want to gain in order to make the pivot as quickly as possible. This requires, in the end, a choice on what you want to concentrate on. That being said, you probably want to get going before you have to make a final decision. The good news is, there are some basics to get your started and give a good grounding in pretty much anything that you want to work on eventually. This is kind of the path that I’m following right now.Start at the beginningLearn about the basics! Before you learn anything more advanced, you need to know the building blocks that all of those more advanced skills are built upon. Learn as much about operating systems as possible, especially Windows and Linux. Yes, learning macOS is helpful too, but there are a couple of things there: there aren’t that many jobs specifically working on just macOS, also it’s heavily based on BSD (especially on the command line, where you will often feel like you live) and so learning Linux will let you get around in macOS just fine. Linux and Windows are both important, though depending on which way you want to go, one might well be more important than the other, but you won’t regret knowing about both of these major OSes in a tech career. A large number (Can I say most? I want to say “most” here.) of large businesses/enterprise clients are going to utilize Windows Server and Active Directory. There’s really not a good turnkey solution out there (yet…and at least that I’ve seen…I’d love to be wrong here, leave me a comment below if I am!!) that compares to AD and its many associated parts. Linux, on the other hand, runs the world when it comes to the internet and servers in general. Knowing both operating systems well can only help your career.But which Linux distribution should I learn?Well, most of what you learn on one will work on the others. The biggest difference between the distros are in how they get updates, how up-to-date the software is in their repos, and what package manager they use to access those repos. The rest of it is pretty easy to change. Don’t like GNOME? Install KDE. Need a light-weight GUI for a low-powered server, but you don’t wanna use the command line for everything? I like XFCE for that. Back to the distro question: which one? Honestly, I generally use Debian-derived distributions because that’s what I’m most familiar with. I went through my “I run Arch” phase, but honestly Arch is too easy to break for a production system, at least for me. A lot, like a lot-a-lot of businesses use some form of Red Hat Enterprise Linux (RHEL) or its derivatives. For my own Linux-based personal system, I use Fedora. A lot of businesses will use RHEL itself, or some other derivative meant for stability. Used to be, that was CentOS, but its release methodology has changed, and so there are a lot of “contenders” out there for it’s title. Rocky Linux and Alma Linux are the two that come to mind, but that’s not important. Learn how to use the various package managers for those distributions, then pick one that you like with a desktop environment that you enjoy, and just use that. The advent of Flatpak and (shudder) Snaps, along with AppImages make it much less important when looking at what packages are in a repo. I like Fedora’s take on this (which is why I use it for my desktop), where they eventually want to get things moved to OS-level software and apps coming from their repos, keeping the OS itself super stable. Other apps, however, would be installed (ideally) via Flatpak, which allows developers to update their app in a single place, package it once, and have it work across all of Linux. Since this keeps the distro out of packaging most software, this gives you a higher likelihood of being able to install the most current version of software. This has been a problem with particularly Debian-based systems for a long time, as Debian focuses primarily on stability…which led to really old versions of apps in their repos.TL;DR - Pick one. It doesn’t really matter. Just learn the different package managers as well as “Linux” in general.Learn networkingIf you’re going to be doing anything that might have to do with networking (and this includes the policy people, since you have to…should, anyway…understand what you’re writing policy for) then you should at least learn the basics of networking. You don’t have to be an expert, but you should at least know what the OSI Model is, where to look it up, and not look confused when people say “Layer 2” or “Layer 3” networking. Also, subnetting. That arcane discipline will help you a lot in setting up and understanding the layout and functions of networks.Learn some codeYou don’t have to learn code like you’re going to be a Developer…unless you want to be a Developer, or just like it, or whatever reason. Still, learning the basics of coding is just going to help you. You should at least be able to understand program flow (conditional statements, functions, returning values, looping, what is a “class” and how to use it, etc.) so that you can follow along with what an app is doing. Also, if you’re working in tech, you’ll likely want to automate something at some point. The easiest way to do that is through some basic code. Frequently you’ll see shell scripts for this, but it’s not at all uncommon to see Python used as well, since it’s included by default in almost every Linux distro…as well as in macOS and (I think) BSD. I should really spin up a BSD instance to see what’s changed, come to think of it…the only thing that I use based on BSD is my firewall, and I don’t think I’ve ever actually needed the command line for that. The point is, though, that having at least a basic idea of coding-know-how will only help you…both to understand and to create basic automation, and also in landing that job. Knowledge of a scripting language is often a request, or more. Learning HTML/CSS is also a good thing for everyone, so that you can at least know what you’re looking at. Same goes for JavaScript. I’d advise knowing at least the structure and basic syntax (well enough to recognize it, at least) for a few languages. For me, that’s Python, JavaScript, Go, HTML/CSS, Swift, BASH, and some old knowledge of C and C++ that I haven’t used for years. Thing is, I used to want to be a developer, which is how I ended up knowing bits and pieces of all of these things. I kind of collect programming languages. I picked up the basics of Go because (if you’re going into security) a lot of security tools are being written, and even re-written in Go from Python, just because it’s faster. I still prefer Python, but knowing how Go works has already been beneficial.Soft SkillsThese aren’t going to be listed in many tech job descriptions. It doesn’t mean that they aren’t important. In most cases, I’d say that they’re more important to the company than the tech skills. If you already know the basics, the company can train you on specific tech skills much easier than they can train you in conflict resolution, empathy, negotiation, and de-escalation. Also, the ability to speak or write clearly, and explain things to people that are not in your field is exceptionally important. Explaining to an executive about container escapes or SQL injection is going to get you glazed eyes, a confused look, and “That sounds like it’s out of our budget for right now.” Being able to explain technical terms and functions simply to people that aren’t in the field is super important. If you know about their field (usually business or finance) then relate to them in their terms. You have to meet people where they’re at, and explain it to them in a way that they will understand. This is going to reduce confusion, make it less likely for there to be resentment. “I can’t stand talking to that guy! It’s like he’s always talking down to me because I don’t understand what he does. Maybe I should make him listen to how depreciation affects the value of his hardware, and how that determines when and if he gets new toys?” This isn’t the attitude that you want people to have. (As a side note, I am totally down for that conversation!)Soft Skills in daily useSure, talking to bosses is one thing, but maybe you don’t have to do that often. Your boss is a tech person too, so they speak the language. Great! That means that your day-to-day work may go smoother. Think about it, though: have you ever seen conflict between people in the office? Have you ever had an angry customer (internal or external)? The answer to both of those questions is either “YES!” if you’re not lying to yourself, or else you’ve probably never had a job. Conflict is part of our existence, and is going to happen whenever you get more than one to two people together for any length of time. It may not be angry conflict, but still there will be conflict. Conflicting views, divergent vision, workflow requirements that don’t jibe with how you want to handle things, are all low-level conflict. Being able to deal with that effectively and professionally, and being willing to bend (at least some) in order to follow the best practices of your team is critical.But I work from home now! Soft skills are useless to me!Um. I’ve worked from home since the start of the pandemic. Honestly, soft skills have been more important to me since leaving the office than they were when I was in the office. People are much less likely to “blow up” or just ignore you when you’re right there in front of them. Working at a distance gives enough separation that people are more willing to do things that we would find disagreeable. Also, if you’re working from home, communication is an even larger part of your job. You need to keep everyone (co-workers, management, clients, anything regulatory) in the loop as to what and when you are doing things, what has been done, is yet to be done, and what will have to wait or cannot be accomplished currently. Being able to effectively communicate is always going to be vital in business, but when doing business remotely, it’s critical to keep things flowing.OK, That’s Nice…So Which is More Important?I’ll take someone with great soft skills and only the bare minimum in tech skills any day. They have that minimum, so I know that they can learn, and that they have taken the time to do so. I can teach someone to access an SQL database if they never have before, especially if they’re comfortable on the command line. (Yes, I prefer to use PGadmin too…work with me here) I don’t want to have to attempt and teach someone how to care about other people genuinely. I don’t want to have to teach them how to handle interpersonal conflict. I’d say that for actually working in the field, soft skills are the most important to have up front, as long as you do know at least the basics of the tech skills. Learning more than the basics is always going to be better! Don’t take away from this that I don’t think you need to know tech skills! You need to know both…but if you can spin it the right way, then having those soft skills becomes more important than specific tech skills. If you’re switching careers from something less tech related, then lean into those skills. People with management and sales experience, particularly, can be valued: we know how to “pitch” ideas in a way that business and finance people can understand and accept, and know what sorts of risk they aren’t going to want to deal with.ConclusionSoft skills are likely the most important skills for you to have…but this cannot be at the expense of your tech skills. Make sure that you understand the basics of business and the like, and that you know how to talk to people. Know at least the basics of the tech skills that you’ll need. If your soft skills are well developed already, then you can move from there into learning more advanced tech skills which will help even more with landing that job. If you have doubts about this approach, consider this: How’s that first interview going to go? The one where you actually talk to someone. Tech skills are something you talk about in an interview. If you don’t know how to talk to people, then you’ll likely come off as an arrogant ass, or else someone who just can’t deal with people face to face. Those aren’t disqualifying things, for a lot of jobs in tech…but which one is the hiring manager (or HR person/recruiter, frequently, for that first interview!) going to prefer? The tech skills get your foot in the door from your resume. The soft skills are going to land you the job." }, { "title": "100DaysOfHomelab 12/100 - Learning and RL Conflicts", "url": "/posts/100DaysOfHomelab-Day12-Learning-and-RL-Conflicts/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, docker, container, docker-compose", "date": "2022-09-22 00:00:00 +0000", "snippet": "Today’s more learning. I’ve gotten several docker containers working via docker-compose, which is great, but I really need to get the docker networks thing figured out. There’s got to be something super simple that I’m missing that’s making this fail. So, today will be reading and experimenting, and the interminable repetition of: Edit docker-compose.yaml in Sublime Push the edits to GitHub Pull the edits from GitHub on my server hit up-arrow twice and run “sudo docker-compose up -d” Repeat ad-nauseumSo a boring day from the outside. For me, though, I really like troubleshooting this sort of thing, as it’s the best way for me to learn something, so I’m kind of excited.Also today, however, a lot of time was spent with new-hire paperwork, finding a notary that would work as a business representative to witness and fill out an I-9 (yeah, that’s apparently not a thing most notaries do around here, for whatever reason) since I’ll be working remote…and I don’t want to have to mail my physical social security card and driver’s license (I don’t have a passport) across the country, then have them mailed back. The I-9 is one of those super-important forms that is also a massive pain in the rear. They can’t even be (or aren’t supposed to be, anyhow) stored with your employee file…the business has to have a separate storage place for them. When I ran hotels, that was why I had a divider in the hanging file drawer. Exact same titles on the folder tabs…employee files were on the left, I-9 stuff on the right. So there were some hoops to jump through to get everything sorted. Still, I’m really excited by this opportunity, and given that I know the kind of things that are technically required for this stuff, it’s not like it bothers me or I would get upset by it. It’s just a regulation. It’s not like we don’t all deal with plenty of those, right? Unfortunately, this does limit the amount of time I can spend with the homelab today.(Oh crap, I forgot that I have a paper due in school, too! LOL, welp, time to switch writing gears!)" }, { "title": "CIA: At the Intersection of Security and Business Processes", "url": "/posts/CIA-At-the-Intersection-of-Security-and-Business-Processes/", "categories": "Security Thoughts", "tags": "infosec, cybersecurity, confidentiality, availability, integrity, business, usability", "date": "2022-09-21 00:00:00 +0000", "snippet": "SummaryFair warning: I’ve had less than 2 hours of sleep, and this may ramble a bit. See the Table of Contents on the right sidebar to skip to sections.The CIA triad is something that we all pay attention to in this industry. If you’ve been to college for #InfoSec then you’ve had it drummed into you from almost day 1. If you learned in other ways, I seriously doubt that you’ve managed to avoid hearing/learning about the CIA Triad at some point in time. It’s ubiquitous enough that you can find it mentioned fairly casually and often on Twitter threads from both leaders of the industry as well as newbies (Hi!).What is the CIA Triad?The CIA Triad is kind of a basis of what security is, and is (naturally) made up of three parts: Confidentiality Integrity AvailabilityA successful security plan must take in to account all three of these categories. Simple, right? Well…no, not necessarily. Lets look at each of these in turn. I won’t be going into a super amount of detail on these, just a brief, 1000-yard overview.ConfidentialityConfidentiality is what most people think of when they think of Cybersecurity. This is where we make sure that people who aren’t supposed to have access to information don’t have access to that information. Pretty basic, right?Well…when do you need to think about confidentiality? (the answer is a generic yes) Do we worry about confidentiality when the data is being moved around or outside of the system? Of course. Do we care about protecting confidentiality when the data is sitting on our internal hard drives? You bet. Encryption is the most common way of thinking about confidentiality, as it (trys to) prevent access by unauthorized people.Given that, this brings up another part of confidentiality: access control. If you want to keep data confidential, then in addition to encrypting the data “at rest” and “in motion”, you might also want to deny access to the data at all. This is where the Identity and Access Management (IAM) policies for the company come into play.IntegrityIntegrity is the part of security that doesn’t get thought of as much by people outside of the industry, at least anecdotally from what I’ve seen. Data integrity refers to preventing unauthorized modifications to data. Encryption and IAM plays a role in this as well, attempting to prevent unauthorized modification. Consider the sharing of research for, I don’t know, vaccines. What would happen if someone changed the proportions of the ingredients (no, I am not a virologist, work with me here) to something that is fatal when administered to humans? Well, if there are good integrity checks, then hopefully nothing. First, the data should be encrypted at rest and in transit, making it more difficult to modify. Further, nobody except the people who need to have access to that information should be allowed to view it at all, per the IAM policy. Finally, the information should be audited in some way. This can be a manual audit, just to make sure that what comes through makes sense (the common sense check should always occur), or it could be something like comparing a hash of the original file to a hash of the file that arrives. This would reveal any tampering or alterations that have occurred. It wouldn’t show what had changed, however, just that it had changed since it was originally sent. Integrity of data is critical to any business process, and so it’s a leg of the Triad.AvailabilityThis is probably the most-overlooked leg of the triad, at least from what I have seen from people. You can have the best security in the world, with data that is locked up like a safe in the middle of Fort Knox, and access to it provided to only two people, who all have to authenticate via a PIN number, a passphrase, retina scan, voice print, and a hardware token, with ongoing authentication via typing patterns and diction scanning. You can have it hashed in three different formats, so that changes are always noticed, immediately, and the system might even roll it back to a previous, matching version if it detects a change. (This…is not a good idea or setup, by the way…it’s overkill, which is part of the point. Stick with me here.) Every one of those controls is a potential single point of failure. That is…bad, especially when you’re talking about complex technological controls. Also…have you made sure that those two people who need to access the data can actually get to it when they need to? This is where availability comes in. You can have “bulletproof” (ha) security, but if nobody can access their data when they need it, you not only don’t have security, but you don’t have a product. Businesses, naturally, aren’t fans of this sort of thing. Securing your data and infrastructure is important, but if you can’t use it, then it’s a waste of time and money.Which is the most important?You’ll find in some college classes that the correct answer is “All legs of the triad are equally important, and should have equal attention paid to implementation.” Yeah, that’s kind of bullshit. The real answer is: It depends. Security isn’t just about making things harder to mess up by threat actors or accident, it’s primarily about doing those things while also maintaining usability. A business isn’t going to pay you (or shouldn’t) if you “secure” their data and networks, but then the business is unable to function. How did that help? Sure, they won’t get sued or take reputational damage from a data breach…but they’re going to get sued and take reputational damage from the service that people are paying for not being available. One thing I see a lot of people lose sight of is the Cybersecurity is a business function. It doesn’t exist in a vacuum, and it has to play well with the rest of the business. Take the example under “Availability” just above: do you really think that those two people who have to jump through all of those hoops just to access, much less make changes to, that super-important data haven’t found a way to copy that data, work on it on their own workstations and email/message back and forth to work collaboratively with each other? Yeah, I give that 1-2 days, a work week, tops, before that happens. Simply put, if you make things too difficult for people to easily use, then they’ll look for ways to circumvent your controls. These aren’t “malicious insiders” or “threat actors”…these are people trying to do their jobs, which they are also (I hope) being paid for…and you are making their life harder. That just isn’t OK.Cybersecurity and BusinessMost of us are going to be paid by a business to do cybersecurity work for them at some point. This may be as an employee, a contractor, a consultant, or whatever you want to call yourself: we are offering services and/or products to secure a business. This is against both internal and external threats. Some of those threats are honestly accidental. Some are the result of faulty notions or even a simple oversight. Some, naturally, are genuinely malicious. We have lots of different ways to address those issues. That’s the whole reason for NIST and other frameworks, after all. That said, there has to be a balance.I don’t have a whole lot of experience in InfoSec. I do, however, have a whole lot of experience in business, management, project management, HR, sales, tech support, and the like. What I can tell you from that experience is this: they don’t really care. Sure, some individuals do in the higher echelons of the company that will have to approve any new expenditures, but the company itself does not care. The company exists to make money for the owner or the shareholders. That’s it. Remember that, and pitch your ideas with that in mind. This is where the “divide” comes in between the line staff, the middle management, and those in the C-Suites. Small changes might be able to be approved by middle management, provided that they have the budget and freedom to make those sorts of changes. Anything big, though, and it’s going to get kicked up the food chain. Most of those people don’t know you, and don’t really know what you do. They are going to evaluate anything that you propose in a few different ways. Cost/Benefit Analysis: What does this proposal do for me/the company? What is this going to cost? What is this potentially going to cost us if we don’t follow this proposal (&lt;- Lean into this one!) Productivity: Is this going to hamper productivity? If so, how much? Is this going to make my workday more difficult/frustrating? Legal: Is doing this going to get us sued? Is not doing this going to open us up to liability? Does this “check a box” for regulatory compliance? Is this a better thing than what compliance mandates, but we’re going to have to explain it on every audit? (Here’s looking at you, PCI-DSS, and your “wonderfully” antiquated password policies and practices) Is this person going to shut up without me firing them? How will approving/denying this affect my standing in the company and in society if word gets out? How does doing/not doing this reflect on the company?This can give you some pretty good ideas on how to pitch a new proposal. Make it beneficial to the company’s public image, emphasize reputational and legal risks of not implementing the new solution, and make sure that costs can be kept as low as possible and that productivity is minimally impacted, unless you find the unicorn control that increases both security and productivity…that one’s generally get the green light.Cool, but really…Which is the most important?Again, it depends. From a security practitioner standpoint, we frequently focus on Confidentiality and Integrity as a knee-jerk reaction. It’s right there in the acronym: CIA. That’s the standard way of looking at it. While individual executives might not feel this way, a board that doesn’t really understand security, and just wants to not be in legal jeopardy, not lose repuation publically, and spend as little as possible to get that way while still being able to use their product/service. For a business…even fintech businesses that have so many regulations on confidentiality (which is a big part of why those regulations exist…), the order is really kind of reversed. AIC, if you will. From a business perspective: Availability: Can my employees or customers access what they need to in order for them to make/provide me with money? If services, internal or external, are not easily accessible, this immediately affects the business’ bottom line. Would you pay for a service that you couldn’t use? If you were an employee, if using something was a massive pain in the butt that took forever and broke your flow, would you not look for ways around using it? Integrity: Is this the right information? We’re going to lose money if people mess up our stuff Confidentiality: Dang regulations making things hard… Legal trouble if we have a data leak with PII in it, and we were negligent in storing the data. Worse, the reputation hit when it goes public! So how do we work with this?So our job is to make sure that we balance all of these needs. Not everything has to be secured. Try to figure out what the company’s risk tolerance is. Find out what is most important to them, and what they don’t care about. Learn about all of the regulatory hurdles that the company faces. Then, don’t propose a new control or process as something to fix a potential security problem. Remember: most of the actual decisionmakers either don’t know what you’re talking about, don’t care, or both. Make it like a business proposal.This process will lead to better compliance with PCI-DSS requirements and should reduce the amount of time and personnel that we have to assign to our normal audits. The process itself is business-neutral, and can be implemented behind the scenes without any direct impact, positive or negative, on productivity and employee workflow. Not implementing this or some other process to cover [here are the technical parts where their eyes glaze over] will lead to a high risk of non-compliance, with legal and reputational damage far beyond the cost of implementation in the case of a security breach in this manner.(Yes, this is off the cuff. No, it’s not for a specific product, which makes it difficult to write anything decent)Tie the control or process that you’re pushing to how it benefits the business, and tie the lack of that product or service to a detriment to a business. In hospitality and sales, this is the difference between features and benefits. A feature is just something cool that you have or offer. A benefit, however, is a feature that is specifically good for your client/customer. Naturally, benefits are going to weigh more heavily into their purchase/expenditure decisions.ConclusionWhat have we talked about? The CIA triad is important to consider when coming up with controls. Also, our perception as security practitioners is very different from those who run/own the businesses that we work for. Our priorities are different. In order to be successful in a business, we have to be able to present our proposals in such a way that it not only makes sense to the person, but also how it benefits them personally or the company. Think about talking security to your CEO. If you don’t work for a security-focused company, they aren’t going to know what the hell you’re talking about. The CISO? Maybe, it depends on the CISO, but generally they’ll at least speak the language. You have to meet people where they are, and talk to them in a way that they can understand. That’s why I say that soft skills are more important than technical skills in a lot of ways. Sure, you need to have the tech chops, but if you can’t communicate it…it will never matter." }, { "title": "100DaysOfHomelab 11/100 - Docker Compose", "url": "/posts/100DaysOfHomelab-Day11-Docker-Compose/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, containers, docker, docker-compose", "date": "2022-09-21 00:00:00 +0000", "snippet": "SummarySo, this is a day where I’m looking up a lot of things and trying to set some infrastructure up via Docker. In my research and planning, I found out that I need (like, really, really need) to learn Docker Compose. So, I’ve set up a private GitHub repo to hold some yaml. The way that I’ve got it set up right now, I’ve got a directory that contains my general services that I’m usually going to want to be up, called Wyrmhole. I’ve got another folder with it’s own docker-compose file called HackingLab. Eventually, this will be a Kali container (the only one in there right now) as well as several vulnerable machines or other infrastructure. I plan to put this into it’s own, isolated subnet.Networking and SubnetsSpeaking of docker networking and subnets, this is one of the problems that I’m having right now. I want to use ipvlan L3, as L3 networking is just…easier and cleaner, honestly. BUT that’s not working right now. While the network is still in my compose file, it’s commented out at this point. Everything creates and spins up without issue, but I can’t access any of the services…and they can’t access anything outside of the docker network. I do have a static route set up on my router leading to the host computer, and specifying the /24 networks that I was setting up. I was going to have (in the primary compose file) a separate network for general services, one for Grafana-related services, and one for “business” related containers, generally things that I spin up to be able to learn/train on. Right now, I’m in port-tracking hell, trying to keep up with 1-2 ports exposed for something like 7 containers.Current Containers (Proposed)So the current set of containers that I’m looking at having (right now) available all/most of the time:General Heimdall Yacht PostgreSQL Redis Calibre Traefik Log and Info on the Network Grafana Loki Prometheus “Business” containers MidPointCurrent StatusThis is the list of what I’m working on getting up and running in my primary docker-compose file…and it’s definitely a work in progress. Of all of this: MidPoint and Heimdall are working, lol. Yacht was working, but with the docker-compose, it…isn’t. Not sure why yet Still, MidPoint was the one that I wanted to work the most. I’m still having issues with volumes and mounting them. Calibre, for example, works fine. EXCEPT that it doesn’t mount the volume to the correct place. The directory is created, but it’s initialized as an empty directory, with just the default db and default “book” on how to use Calibre. This is the current part of the docker-compose.yaml file dealing with Calibre: calibre: image: linuxserver/calibre:latest container_name: calibre ports: - \"8090:8080\" - \"8091:8081\" restart: always environment: - PUID=1000 - PGID=1000 - TZ=America/Indiana/Indianapolis volumes: - ./calibre-lib:/configAny suggestions? Email me at brian@bpetty.tech, or DM me on Twitter (@matrixwyrm)" }, { "title": "100DaysOfHomelab 10/100 - Research Day", "url": "/posts/100DaysOfHomelab-Day10-Research-Day/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, containers, docker", "date": "2022-09-20 00:00:00 +0000", "snippet": "This is a research day for me!See yesterday’s post about the videos that I’m using for learning about Docker. Docker Networking is going to be a big part of what I’m looking at, so that I can make sure the services that I launch are reachable, while maintaining network segmentation. That said, at this point I’ll just be happy if I can get further services up and running, and I’ll figure out the security part later if need be.I’m thinking that I’ll be looking at an ipvlan l3 network to begin with. I’m not absolutely fixated on this, but it seems like it’s most likely the best fit for what I’m doing. It’s pretty easy to set up a static route to my desktop from my router (already done) but I need to redeploy a container in there to see how it works. I may test it with the MidPoint container that I have up and running, or I may set up something super-simple that I don’t care about, just to test it. Maybe a “Hello World” type of container for testing.Fortunately, I really like doing research, so this kind of day is pretty fun for me. Don’t expect tomorrow’s post to be much longer/meatier than this one, as I’ll likely be still researching for at least half of the time I have for this project." }, { "title": "100DaysOfHomelab 9/100 - Containers are Cool", "url": "/posts/100DaysOfHomelab-Day9-Containers-are-Cool/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, containers, docker", "date": "2022-09-19 00:00:00 +0000", "snippet": "Containers are cool. I’m tempted to write “that is all” at this point. Not a lot of visible progress today. I did get the MidPoint container that I was looking to get up and running set up without issue. I’ve got several others that I’m working on getting up, but I’m having issues with Volumes. As in, even though I (thought that I) had defined the volumes, linking the directory in WSL where I have the library that I want mounted to the internal container directory…it’s just not working.Today I’m watching and reading tutorials on Docker. NetworkChuck’s video on Docker101 is my start point, and I’ll be going through some of my favorite YouTubers that make this kind of content. I always hesitate to use YouTube for this kind of things because I am highly subject to “squirrel” moments. I fully expect to be diverted from my goal today and end up studying K8s already. It’s on the list, but a couple of steps from here, as I want to get some reliable hardware or at least a stable virtual network before I start going into HA and scalability.Playlist that I’m looking at for today: NetworkChuck’s Docker101 video freeCodeCamp.org’s Docker Tutorial for Beginners The Digital Life’s Docker Networking Tutorial Also from The Digital Life: Server Monitoring (with Grafana/Loki) (Told you there would be some squirrelage) NetworkChuck’s Docker Networking TechnoTim’s Virtualize or Containerize TechnoTim’s Meet Grafana Loki (Yes, I really want to get this set up) NetworkChuck’s Docker Compose videoAlso going to be looking at TechHut’s video about ditching the Rasberry Pi" }, { "title": "100DaysOfHomelab 8/100 - Docker and Basics", "url": "/posts/100DaysOfHomelab-Day8-Docker-And-Basics/", "categories": "100DaysOfHomelab", "tags": "homelab, virtualization, containers, docker, heimdall, yacht", "date": "2022-09-18 00:00:00 +0000", "snippet": "SummarySo today, given the demise of the ProxMox project for now, I’ve changed focus. One of the things that I want to get back up and running is a MidPoint container, just to learn on. It’s kind of important for the upcoming job start that I’m looking forward to in a couple of weeks. Given that, I wanted to get Docker up and running on my Windows machine, rather than on a virtual server.This can present some problems, as Windows, well, kind of sucks for running a lot of Docker images that I want to use. The solution (I hope) to this is connecting Docker to my WSL instance. I’ve done this in the past, in a casual way, and it worked out pretty well.I’ve got a few different things that I want to get up and running on Docker, eventually, but the most important ones (short of the MidPoint container) are Heimdall and Yacht. I also want to get Calibre Web Server or COPS up and running, to see if that would be more reliable and/or stable than serving from the Windows PC and connected to a database and files stored on a hard drive plugged in to my router.DockerI’ve gotten Docker Desktop up and running pretty well, and pretty quickly, and it is using the Ubuntu WSL instance on the machine as the backend for Docker itself. Fortunately, Docker makes this pretty easy, and using WSL is now the default behavior for Docker Desktop for Windows.HeimdallSo Heimdall is basically a landing page for accessing and managing Docker services via a Web UI. It’s pretty clean, pretty simple, and well…pretty. Yes, I used that word a lot. Still, it holds true. This was pretty simple to install and get spun up.YachtYacht, if it does what I want it to (and says it does) will allow me to easily spin up and deploy Docker-based services. This is done via Templates to make things easier. Hopefully, this will greatly simplify spinning up common services that I will want to use, and there are a lot in the basic template repository that I’m wanting to exploreConclusionRelatively short post today, but most of it has been in research and reading documentation. Likely, the next several days will be similar, as I try to get Yacht and other services and up and running. After I have everything stable in my base Docker setup, I’ll get that MidPoint container set up, and start exploring further services. I’m looking at setting up something like Traffic, something Plex-like for serving media, something to access and read ebooks, a web server, and get started with Kubernetes and likely some sort of orchestration system, maybe Rancher or similar." }, { "title": "100DaysOfHomelab 7/100 - Troubleshooting and Failure", "url": "/posts/100DaysOfHomelab-Day7-Troubleshooting-And-Failure/", "categories": "100DaysOfHomelab", "tags": "proxmox, homelab, virtualization, hardware", "date": "2022-09-17 00:00:00 +0000", "snippet": "Today (short post, btw) I spent what time that I did on my homelab (more than an hour, less than two) trying to find my way around a dead, possibly bricked, laptop that I was going to use to host ProxMox. And I wasn’t able to do anything with it. I’m sure that there will be lots of frustrations like this as I go. I also haven’t been able to successfully virtualize ProxMox on the Windows desktop that I’m using.There was a reason that I didn’t spend too much time on homelabbing today, though, and it’s a good thing! I start a new job on September 26, and so we did a little celebration today. This also means that eventually (after the bills from being unemployed for so long are caught up) I’ll be able to acquire some basic hardware for setting up my homelab when necessary. Hopefully this will let me build a ProxMox-dedicated computer, with extra NICs and the like for passing through to VMs and Containers." }, { "title": "100DaysOfHomelab 6/100 - A Tale of Life and Broken Hardware", "url": "/posts/100DaysOfHomelab-Day6-A-Tale-of-Life-and-Broken-Hardware/", "categories": "100DaysOfHomelab", "tags": "proxmox, homelab, virtualization, hardware", "date": "2022-09-16 00:00:00 +0000", "snippet": "Welp, the laptop that I was putting ProxMox on is…dead? Maybe? I’m tearing it and the other just like it apart today to see if I can cobble together a working platform. Unfortunately, my processor doesn’t support nested virtualization, and so I can’t put ProxMox in a VM right now, either. Additionally, I finally got a job in the information security space, starting later this month, and so I need to be working on projects that will help me with that, as well.So, ProxMox is likely (unless I can get a laptop up and running) a dead project for now. On the bright side, once I’m working (and thus getting paid) regularly, then I’ll be able to eventually afford some hardware to work on. This is a temporary setback, and more of a refocusing of efforts. I’ll still be homelabbing, I certainly haven’t given up on that, but my next projects (again, unless there’s a laptop miracle) will likely be getting Postgres up and running on a virtual server, and setting up the MidPoint IAM solution, likely in a container, as well.Today won’t prove all that interesting to anybody but me, as I’ll be up to my elbows in pieces and parts, and honestly I think I’ll do a little gaming to celebrate getting a job. I’ve interviewed with these people enough to know that I really want to work for/with them, so that’s certainly something to celebrate!" }, { "title": "100DaysOfHomelab 5/100 - And it All Comes Tumbling Down...", "url": "/posts/100DaysOfHomelab-Day5-And-It-All-Comes-Tumbling-Down/", "categories": "100DaysOfHomelab", "tags": "proxmox, homelab, virtualization", "date": "2022-09-15 00:00:00 +0000", "snippet": "This is going to be a very short one, with hopefully a longer post this evening, if I have time.So I got up today and checked on my HomeLab, as you do. ProxMox is not being served, though it does boot to the command line. Rebooting, I noticed that numerous services are not starting up. This may well be a hardware issue (it’s my former laptop for a reason, after all) or it could be that I borked something in the GUI, even. So today, I’ll be reinstalling ProxMox, uploading .iso images for it, and then reinstalling OPNsense. Ironically, I did take a backup of OPNsense after I got the basics set up, but it was saved to the local folder in ProxMox! The first thing that I was planning to do today was going to be to move that backup to some network storage in a different location. Ah well, lessons learned." }, { "title": "100DaysOfHomelab 4/100 - ProxMox...Finally!", "url": "/posts/100DaysOfHomelab-Day4-ProxMox-Finally/", "categories": "100DaysOfHomelab", "tags": "proxmox, homelab, virtualization", "date": "2022-09-14 00:00:00 +0000", "snippet": "SummaryFinally I’m getting to installing ProxMox. This has…not been a seamless process! I had a couple of problems right out of the gate: I didn’t have an ethernet cable, and ProxMox does not include the tools necessary to connect to WiFi out of the box ProxMox really wants you to buy their subscription. So much so that the non-subscription repository is not enabled by default, but the enterprise repo (requiring a subscription) is. This could be so easily avoided by simply giving the user the choice (with the warning message) that non-subscription versions are not safe for a production environment. This is vehemently opposed by ProxMox staff in their forums, however. Great software. Great support, even. Terrible attitude towards the community. When trying to connect to the web interface, I got a blank screen.FixesNo ethernet cable: I stole the one from my desktop Windows PC temporarily.Subscription: This was simple enough, once I figured out what was going on. You first edit the /etc/apt/sources.list.d/pve-enterprise.list file in the text editor of your choice. Comment out the single line in this file, then save and exit. Next, edit the /etc/apt/sources.list file in the text editor of your choice. Add this line to the bottom: deb http://download.proxmox.com/debian/pve bullseye pve-no-subscription then save and exit. Now, you can apt update and apt upgrade without errors. Instructions for this can be found in the ProxMox WikiBlank Screen on the Web Interface or No Response: First, make sure that you’re connecting to https://[your_proxmox_ip]:8006. The https part is critical, as http will fail. If that didn’t work, try a different browser or a private window (or clear your cache) Next, if that didn’t fix the problem, then you’ll need to log in to the server as root. This can be done on the physical machine (I used a laptop, so this was pretty easy for me), or you can ssh to root@[your_proxmox_ip. Login is root and the password will be what you set during installation. Follow the instructions in the ProxMox Forums You might try restarting the services with systemctl restart [services_starting_with_'pve'] Main thing that might work is reinstalling some packages that deal with the web frontend. Run apt install --reinstall pve-manager as root and check to see if it worked Run apt install --reinstall proxmox-widget-toolkit as root and check to see if it worked My particular situation required using a private window. It still does, don’t know why, but at least I can access it!Setting UpGreat setting up instructions video here: Techno Tim - Virtualize Ubuntu Server with ProxMox VEThis video uses an older version of ProxMox than current, and an older version of Ubuntu Server (it’s from 2020) but the basic instructions still work. I’m working through this as I type this post, so if I see anything major that has changed and I have to figure out, I’ll note it below. Upload the ISOs that you need to your local ([server_name]) storage. Just expand your server (under ‘Data Center’ on the left hand side) Select the local storage Click the ‘Upload’ button to upload from local storage, or click ‘Download from URL’ and paste in the URL for the ISO I had to do OPNsense from my local computer, as it downloads as a .bz2, and I had to decompress it first Right click on the node that you have, and select ‘Create VM’ Go ahead and configure Memory Ballooning during setup If you’re installing (as I was) OPNsense or something similar, be sure to add a Network Interface from the Hardware tab for the VM before you boot it up. I didn’t, and had to restart, but that’s not such a big deal. The Console tab lets you access your VM from the web interface, without needing to directly SSH in Start your VM, and install the OS as usual.Installing OPNsenseThis is pretty straightforward. Make sure that the ISO you downloaded from the OPNsense Download Page is the ‘DVD’ image type When it boots up, don’t log in with root. Login: installer Password: opnsense Select the options that you want, I do recommend going ahead and changing the root password to something better. Once everything is installed, reboot From there, log in as root (using either opnsense as the password, or the new password you set) Make sure that the interfaces (there should be two) are both showing up. If not, select option 1 to assign interfaces to WAN and LAN Assign the interfaces if there is a specific IP address that you want to use, or if they are on the wrong subnet. From there, you should be able to connect to the web interface for OPNsense! Run through the setup wizard Make sure to UNCHECK ‘Block RFC1918 Private Networks’ when configuring the WAN interface, as otherwise your router/firewall won’t accept incoming connections from your home network! From here, just install any packages that you want to and/or set any configurations that you want." }, { "title": "100DaysOfHomelab 4/100 Part Deaux - Setting up OPNsense (basic)", "url": "/posts/100DaysOfHomelab-Day4-Part-Deaux-Setting-Up-OPNsense/", "categories": "100DaysOfHomelab", "tags": "proxmox, homelab, virtualization, OPNsense, firewall, router, dns, ssh, certificate", "date": "2022-09-14 00:00:00 +0000", "snippet": "SummarySetting up OPNsense isn’t exactly easy to set up, but it’s not overly difficult, either. The UI is phenomenal, and easy to understand. Pro tip: turn on the ‘full help’ toggle in the upper-right of the details page for configurations. This turns on all of the help text, and makes understanding what the (sometimes strangely named) option is for. Further, the plugin support is great and has lots of different options, all of which come with actual descriptions, instead of just a one-liner.Updating OPNsenseThere are two basic ways to do this: In the lobby/dashboard when you log in, there is a link to Click to check for updates. link. Click it to check for updates immediately Alternatively you can navidate there from anywhere in the system by: Click System from the navigation menu on the left to expand it Click Firmware to expand it Click Updates to check for updates In addition, I had an error with the web interface updating. To fix it, I had to log in via SSH (because the Console in ProxMox also wouldn’t connect) Option 12 in the menu is what it takes to update the server from the console. Setting up a local CAAfter updating, setting up a local CA is the first thing that I do. This is a necessary step for many services in setting up the firewall. After setting up the CA, you’ll want to come back here whenever a service requires a certificate, and create it.Steps: Click System on the left-hand navigation bar to expand it. Click Trust to expand it. Click Authorities to get to the screen where you can add a CA Click the + in the upper-right hand corner of the page. Give a descriptive name to the server Select Create an internal Certificate Authority from the dropdown on the Method line Select a Key type on the appropriate line. I chose Elliptic Curve I left the Curve line at prime256v1 I changed the Digest Algorithm option to SHA512. I left Lifetime alone (825 days was default for me) The Distinguised Name section should be filled out as much as you like, but enough to identify your server if necessary Click Save once finished Now you have an internal CA, and can issue certificates from it by selecting Certificates on the left side Adding a Revocation List can be done from the left side as well.General HousekeepingNow is a good time to click through and check that settings were properly applied during the setup wizard, or to fill in anything that you left blank. Going through the navigation menu will also give you a good idea of what services come as standard in OPNsense, and let you start planning what plugins you want to find and set up. Good things to check: System Access Create a new user with a complex password here and store it in a password manager I also add this user to the ‘admins’ group and check the box to create a user certificate I did also check the box to set up a One Time Password. This was added easily in 1Password (the password manager that I use) I clicked the Click to unhide button In 1Password, I edited the saved login for OPNsense I added a OTP field I clicked the option to scan a QR code. Older versions required moving a viewfinder around on the screen. This newest version just finds it and adds it automatically. I don’t even know if this is usable, or if I need to install another service to use it yet, but we’ll see soon enough. I did not create any new servers, though this is where you can add an LDAP or RADIUS server, among others Configuration Backups This is where you can backup and restore configurations. I’m not ready for this step yet, as I want to get things set up first. Google Drive is also available as an option for backups, if you wish Defaults - Reset the server to default values Firmware This is where you go to update and to install plugins. Skipping this section for now, as I’ll do plugins last, and have already updated Gateways You should see at least 1 entry here, sometimes 2, depending on if you enabled IPv6 The ‘WAN_GW’ gateway should point to your main router/modem High Availability This doesn’t apply to me right now, as I need more hardware for that, but if you’re setting this up as HA, here’s where Settings Administration This is where you can set up how you access the server Selecting the specific certificate you want to use for the site, alternate hostnames, etc. Cron Set up Cron jobs! General Allows you to set up things like the Hostname, the domain, timezone, etc. Most of this should have been set by the wizard Logging / targets This will let you set up a target to send logs to. This will likely be useful once I get around to setting up actual security tooling, like a SIEM Miscellaneous Set up power usage options, hardware acceleration for cryptographic functions, set up periodic backups, etc. Tunables Yeah…no. I am not ready to tackle this page yet! A little too far in the weeds for me so far. Interfaces Check LAN and WAN here to make sure that they are assigned to the correct addresses I didn’t have to change any options, except to prevent the removal of the interface, just to be safe In Assignments, make sure that you do have the right interface assigned to the right function (LAN/WAN) I didn’t mess with anything else in here, yet Firewall Look through it, I’m not adding anything to this yet, as I’m not ready to actually make this my router. VPN IPsec and OpenVPN are the two default options, though others can be added through plugins This is one of the main features that I want to get set up and running, but not yet. I want things like a DNS Resolver up and running first. Services This is where a lot of plugins that you install will show up Intrusion Detection I did turn on Intrusion Detection (IDS), but did not turn on the IPS system, as it would be pointless right now. Enabled syslog alerts Selected both LAN and WAN for interfaces. Network Time I left this as-is, just making sure that all four opnsense NTP servers were selected Unbound DNS Unbound DNS is the default service installed in OPNsense to handle DNS serving. I just make sure that this is enabled, and that DNSSEC is enabled. I don’t select any of the DHCP options, as I’m not currently using this as a router, and so have DHCP disabled. Checked this on my phone by turning off mobile data, and setting the DNS server for the WiFi network to manual, and entering the IP of OPNsense. It worked with no issues! Closing ThoughtsSetting up OPNsense wasn’t that big of a deal. I’m sure it would be (somewhat) more challenging with passed through NICs, but that’s not where I’m at right now. Further, plugins will add a great deal of complexity, I am certain, but again, I’m not there yet. I’m not sure what I’ll be doing tomorrow, yet, but it might be looking at plugins for OPNsense, or I might set up a different virtualized server." }, { "title": "100DaysOfHomelab 3/100 - More Sidequesting", "url": "/posts/100DaysOfHomelab-Day3-More-Sidequesting/", "categories": "100DaysOfHomelab", "tags": "jekyll, homelab, website, blog", "date": "2022-09-13 00:00:00 +0000", "snippet": "Blog updateWell, Jekyll and Chirpy together look great, and so far it is great! That being said, there are some…quirks…with how the posts and tabs work, especially with the test server.Some of these quirks: Show favicons Show new tabs When adding a new tab, the local build breaks. Now, when I build it on my machine it just puts the images in the root folder (_site/) and doesn’t serve anything but an index to that directory. I have to push to GitHub and use it’s Jekyll Build action to see the results of changes Horizontal rules are weird. Sometimes they work. Sometimes, they comment out the code.Most of today has been spent updating my blog site to include my resume, and formatting that somewhat. I’ll be working on that for the rest of today, likely. Next steps is to try using HTML to center some content on the resume so that it isn’t all left-justified. That’s great for a normal blog post, like this one, but not so good for a resume.ProxMox…when?I’m enjoying this blog quite a bit, as well as working on the homelab. I took today to work on it as I realized something fairly important as I was getting ready to install ProxMox on my old laptop: I don’t have a network cable. Total facepalm moment. I may still do the install tonight, but likely won’t have it up and running until tomorrow at the earliest.Future projectsWhat does the future hold? Well, that’s a pretty big question, and there’s lots of stuff that I want to do. A load balancer for the network I’m considering either a free/community Kemp load balancer, or just using haproxy on the firewall A development server Developing on a Mac is pretty nice. Developing on Windows is…meh. I’d really like to spin up a usable VM that I can develop on VPN access I’m not terribly interested in an always-on VPN…it’s just not necessary for most things. I do want to have a VPN available to me that will allow me to (more) safely use public WiFi. I run a local Calibre server for all of my ebooks. We have a…lot of ebooks. Just as an example, when my wife and I first moved to Indiana, we were living for a time with her mom, until we found our own place. We didn’t have space there to store all of our stuff, so we stored it in a spare bedroom at her dad’s. It was a little while until we tried to get our stuff out of there (lots of weird conincidental things derailing that) and it turned out that the roof over that room leaked. I lost over a thousand paperbacks due to water and mold damage. We have more ebooks than that, easily. Did you know that Paizo sells pdf copies of their rulebooks cheaper, and that they’re often in Humble Bundles? A server to…serve stuff I already have the storage for the above-mentioned Calibre server on a drive attached to my current router, but I’d like to use that for backups, and have the actual server running on its own VM. Currently, the Calibre app resides on my Windows desktop, as it has plenty of processing power and memory to handle it. I’d just like to offload and virtualize it. Containers! I’m specifically interested in setting up scalable and resilient clusters. High Availability We’re getting pretty far in the future here, but eventually I’d like to have enough physical machines to set up high availability services. OPNsense will be the first thing that I try to do this with, as it will be serving (hopefully by this point) as my router, firewall, VPN, and DNS server Then, on to serving a Kubernetes (or other, as something new might come out by then) cluster in HA mode. Maybe Rancher? There are at least some decent tutorials on that one out there. Home Automation By the time we get to this point, Matter will likely be out. Maybe. Someday. I’m hoping to utilize something like Homebridge if it hasn’t come out widely, or if it isn’t all that it’s cracked up to be. I do prefer using Apple’s Homekit devices where possible, as they do offer better security out of the box in most cases (be careful, though, as not all do!) Local CI/CD pipeline I really want to get this going, probably sooner than where I have it in the list here. DevOps/DevSecOps is something that I’m interested in, but haven’t really worked with hardly at all. Game servers My son likes Minecraft. I like to build things in games. Cacheing content server for Steam? Not sure about this one, but it would be handy if I could build a box with enough storage to make it usable and feasible. Self-Hosting this site Again something that I probably should have put in earlier. I’d like for the bpetty.tech domain to just point to my home network. Yes, there’s going to be plenty of segmentation, firewalls, hardening, and such before I do this and open it to the public. This will likely be right after I figure out the CI/CD pipeline, as I really appreciate the code checks and automatic build when I push changes to this site on GitHub Local git server I mean…why not? Actual physical improvements A rack Actual servers NAS or SAN I’m looking at setting up a server with a large amount of storage at some point This would partially be used for backups and snapshots, but also for regular files. If I have access to the home network remotely, then I wouldn’t necessarily need as much storage on mobile devices Plex I have stacks of DVDs. My wife loves movies, I like several series. I’d love to have this set up so that I can stream both locally and remotely. Storage and compute have to be there for this, though, so right now it’s not happening Experiments! This is one of the main reasons that I want to do homelabbing. I’m always interested in trying out new applications, and when I have the money I like to play with hardware. Given that, experimentation is going to be a big theme for me once I have the basic infrastructure set up. " }, { "title": "100DaysOfHomelab 2/100 - Side Quest - Jekyll", "url": "/posts/100DaysOfHomelab-Day2-Side-Quest-Jekyll/", "categories": "100DaysOfHomelab", "tags": "jekyll, homelab, website, blog", "date": "2022-09-12 00:00:00 +0000", "snippet": "Side Quest: JekyllSo yesterday, the goal for today was to set up ProxMox on an old laptop that I have sitting around. That’s still on the agenda, but this is a “SQUIRREL!” moment for me. I wanted to set up a blog page/site for my homelab journey. So, I used Chirpy as a template on GitHub (https://github.com/cotes2020/chirpy-starter), like the one used by @TechnoTim in his documentation site (https://docs.technotim.live/posts/jekyll-docs-site/). I wanted basically the same things, such as a dark theme and some of the customizations. While sure, I like to build everything from scratch as a learning experience, I’m not a front-end dev. I like using templates where possible for web pages and sites. I even thought about using WordPress or something like that, but WordPress has a ton of vulnerabilities if it’s not set up juuuuuust right. I am not that person at this point in time, and so I wanted to use a static site generator. Since I found the idea for #100DaysOfHomelab from @TechnoTim, I looked through their videos on YouTube and found his tutorial for Jekyll, which you can see from the link to their docs page above.This isn’t done yet. As a matter of fact, this page can’t even be read right now outside of my machine (it DOES work on my machine!) because I have to sort out some SSL stuff with Cloudflare and GitHub to get it set up on Pages. Eventually, I’d like to take this back to my homelab, once I have a stable environment, and host it from there. The https site is now live, fixed the DNS error that was causing it to fail. https://bpetty.tech if you are on the standard http site.Things to happen before that: Stable ProxMox server running on bare metal (No VM for this one) OPNsense firewall/router stable A load balancer: either for OPNsense using HAProxy or a Kemp load balancer…or something else that I haven’t seen yet An SSL cert for the load balancer NOT from a self-hosted CA Another stable (virtualized) server for me to host it on Alternatively, a High-Availability container cluster (Rancher, maybe) to provide failover and scale, as much as I can with my home internet bandwidth It’s going to be a fun ride. I may actually get to the ProxMox server tonight, at least the base install, but there are (unfortunately!) other things to do." }, { "title": "100DaysOfHomelab 1/100 - pfSense and OPNsense", "url": "/posts/100DaysOfHomelab-Day1-pfSense-vs-OPNsense/", "categories": "100DaysOfHomelab", "tags": "pfSense, OPNsense, firewall, router, homelab, virtualization", "date": "2022-09-11 00:00:00 +0000", "snippet": "100DaysOfHomelab 1/100pfSense and OPNsenseSo today marks the “first” day for me of #100DaysOfHomelab. It’s the first one that I’m counting, since I just found the idea. So I’ll just start where I’m at now.I have worked for a while homelabbing with virtual machines. Nothing long-term, usually just a project that I’m working on to learn something, with a temporary VM network, using either VMWare Player or VirtualBox. (There was this one time, with libvirt…) Anyway, I started working with pfSense this time to set up a bridge between specific hosts in an otherwise completely segregated virtual network. I was setting up a group of servers as a penetration testing lab, and I wanted to be able to upgrade my Kali install, but didn’t want any vulnerable images that I spun up to be accessible to the rest of the network. Took a couple of hours to figure it out, but it ended up working just fine. I had watched some Lawrence Systems videos about pfSense in the past out of curiousity, and remembered one about pfSense vs. OPNsense, so I thought that I’d give OPNsense a try to, which brings us to today.Both of these are exceptional products, from my brief time with them. That being said, I do like the fact that the community edition of OPNsense gets more updates than pfSense. I mean, if I’m putting up a firewall then I expect it to be somewhat secure. Running a significantly older back-end does not fill me with confidence on that front. Still, it’s BSD-based, so it’s not a complete deal-breaker for me. What really is making me want to stick with OPNsense after trying it today, however, is the layout. I just like it better. Other small quality-of-life things like descriptive information in the plugins page, the ability to toggle on “advanced mode” and “help”, and just the larger variety of plugins that seem to be readily available are also swaying me in the direction of working (first) with OPNsense. Now, I’m not saying that pfSense doesn’t have those things…but I also don’t know if they do or not, and this comes “out of the box” in a better state for me, so that’s what I’m going to be going with for now, at least. I’ll no doubt change my mind on this, likely numerous times, over the days ahead. For me, that’s what homelabbing is all about, anyway…experimentation and learning.Though I do want to keep with the experimentation and learning part of things, I’m also wanting to build out some actual, workable infrastructure for my home network as well. This is sort of the first step to that. I have Comcast as an ISP. That’s not necessarily a bad thing, and it’s really the only option that I have right now, and don’t have too many complaints about it at this point. That said, I want to run my own DNS servers. I want to have access to my home network when away from home (and a VPN for when I’m on hotel wifi). Heck, I want to be able to serve this site in a high-availabilty setup from my house, and tons of other stuff. So homelabbing is something that I’ve been enjoying getting started in, and something that I’ve already planned to do for a long time. The 100DaysOfHomelab are more of a way for me to hold myself accountable (though I’m not going to be upset if I miss a day…life happens, and I’ll just “make up” the time later) and chronicle my progress for myself.Next steps: I have an older laptop with 32 gigs of RAM, a terabyte of storage, and an 8 core/16 thread processor. The only downside is the single NIC. Still, I plan on trying to get it set up as a ProxMox server next, and the first thing that will be going on it is OPNsense. If nothing else, it will be my main household DNS server, with fallback to…something else. I’ve been trying to avoid Google services as much as possible, and CloudFlare has had…issues…lately in the community. Those were my two go-to public DNS servers, so I’ll have to do some research on that as well." } ]
